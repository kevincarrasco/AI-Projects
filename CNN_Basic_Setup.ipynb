{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1r7QIOEh0gLPVgVtC+Zj4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kevincarrasco/AI-Projects/blob/Image_Classifiers/CNN_Basic_Setup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The idea behind the CNN is to filter the images before training the Deep NL.\n",
        "After filtering the images features within the imaes then will come to the forefront and spot those features"
      ],
      "metadata": {
        "id": "9elbtLhuejQJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A filter is a set of multipliers.\n",
        "Internally it will multiply the pixel values and the neighbor values by the values in the filter"
      ],
      "metadata": {
        "id": "9cg6RSKCejiM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This can be combine with pooling which goups up the pixels in the image and filters them down to a subset. The CNN has the ability to learned the filters. As our image is fed into the CNN layer a number of randomly initialized filters will pass over the image.\n",
        "The results of this are fed into the next layer and matching is performed by the neural network.\n",
        "Overtime the filters that give us the image output that give us the better matcheswill be learned and this process will be called featured extraction."
      ],
      "metadata": {
        "id": "jVmVHUYYejk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "cPuX-qsvpny1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu',\n",
        "                           input_shape=(28,28,1)),#this layer take the input and specifies the input shape\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),#MaxPooling will compress the image and enhance the features\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'), #stacking CNN will break down the image better and learn from abstract features\n",
        "    #will generate 64 filters to multiply across the image\n",
        "    #each epoche will figure out the best signals to max the images to their labels and learn which parameters work best in the dense layer\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),#MaxPooling will compress the image and enhance the features\n",
        "    tf.keras.layers.Flatten(),#input layer\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),#dense layer\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)#output layer\n",
        "])\n",
        "\n",
        "##folowing this methodology the network learns from the features of the image instead of just the raw pixels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPOPQS35gdjq",
        "outputId": "5629e8a6-ff32-484c-da8a-c3c64499cc18"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w79Numrbp-hl"
      },
      "execution_count": 2,
      "outputs": []
    }
  ]
}